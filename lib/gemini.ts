import { GoogleGenerativeAI } from "@google/generative-ai";
import { geminiStats } from "./gemini-stats";


// Initialize Gemini API - FORCE reload from environment
const apiKey = process.env.GEMINI_API_KEY?.trim();

console.log("=== GEMINI INITIALIZATION DEBUG ===");
console.log("API Key Status:", apiKey ? `Found (${apiKey.substring(0, 10)}...)` : "MISSING");
console.log("Full Env Keys:", Object.keys(process.env).filter(k => k.includes('GEMINI')));

if (!apiKey) {
    console.error("CRITICAL: GEMINI_API_KEY is missing in environment variables!");
}

const genAI = new GoogleGenerativeAI(apiKey || '');

// ============================================
// ğŸš€ RATE LIMITING & CACHING SYSTEM
// ============================================

// In-memory cache for responses (simple LRU-like cache)
interface CacheEntry {
    response: string;
    timestamp: number;
}

const responseCache = new Map<string, CacheEntry>();
const CACHE_TTL = 5 * 60 * 1000; // 5 minutes cache

// Rate limiter: Track API calls to avoid hitting 15 RPM limit
const rateLimiter = {
    calls: [] as number[],
    maxCallsPerMinute: 12, // Conservative limit (below 15 RPM)

    canMakeCall(): boolean {
        const now = Date.now();
        const oneMinuteAgo = now - 60 * 1000;

        // Remove calls older than 1 minute
        this.calls = this.calls.filter(time => time > oneMinuteAgo);

        return this.calls.length < this.maxCallsPerMinute;
    },

    recordCall(): void {
        this.calls.push(Date.now());
    },

    async waitForSlot(): Promise<void> {
        while (!this.canMakeCall()) {
            geminiStats.recordRateLimitHit(); // Track rate limit hit
            const oldestCall = this.calls[0];
            const waitTime = (oldestCall + 60 * 1000) - Date.now() + 1000; // +1s buffer
            console.log(`[RateLimiter] ëŒ€ê¸° ì¤‘... ${Math.ceil(waitTime / 1000)}ì´ˆ í›„ ì¬ì‹œë„`);
            await sleep(waitTime);
        }
    }
};

// Request queue to serialize API calls
let requestQueue = Promise.resolve();

function sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
}

// Generate cache key from prompt
function getCacheKey(prompt: string, isJson: boolean): string {
    return `${isJson ? 'json' : 'text'}:${prompt.substring(0, 200)}`;
}

// Check cache for existing response
function getCachedResponse(cacheKey: string): string | null {
    const cached = responseCache.get(cacheKey);
    if (cached && (Date.now() - cached.timestamp) < CACHE_TTL) {
        console.log(`[Cache] âœ… ìºì‹œ íˆíŠ¸! (${Math.floor((Date.now() - cached.timestamp) / 1000)}ì´ˆ ì „)`);
        geminiStats.recordCacheHit(); // Track cache hit
        return cached.response;
    }
    return null;
}

// Save response to cache
function cacheResponse(cacheKey: string, response: string): void {
    responseCache.set(cacheKey, {
        response,
        timestamp: Date.now()
    });

    // Simple cache cleanup: remove old entries if cache is too large
    if (responseCache.size > 100) {
        const oldestKey = Array.from(responseCache.entries())
            .sort((a, b) => a[1].timestamp - b[1].timestamp)[0][0];
        responseCache.delete(oldestKey);
    }
}

// Exponential backoff retry logic
async function retryWithBackoff<T>(
    fn: () => Promise<T>,
    maxRetries: number = 3,
    baseDelay: number = 1000
): Promise<T> {
    let lastError: Error | null = null;

    for (let attempt = 0; attempt < maxRetries; attempt++) {
        try {
            return await fn();
        } catch (error: any) {
            lastError = error;
            const msg = error.message || "";

            // Only retry on rate limit or server errors
            if (msg.includes("429") || msg.includes("503") || msg.includes("RESOURCE_EXHAUSTED")) {
                const delay = baseDelay * Math.pow(2, attempt);
                console.log(`[Retry] ì‹œë„ ${attempt + 1}/${maxRetries} ì‹¤íŒ¨. ${delay}ms í›„ ì¬ì‹œë„...`);
                await sleep(delay);
                continue;
            }

            // Don't retry on other errors
            throw error;
        }
    }

    throw lastError || new Error("ì¬ì‹œë„ ì‹¤íŒ¨");
}

// Helper to get response text safely using ONLY the working model
async function generateWithFallback(prompt: string, isJson: boolean = false): Promise<string> {
    // Check cache first
    const cacheKey = getCacheKey(prompt, isJson);
    const cached = getCachedResponse(cacheKey);
    if (cached) {
        return cached;
    }

    // Queue the request to avoid parallel calls
    return new Promise((resolve, reject) => {
        requestQueue = requestQueue.then(async () => {
            try {
                // Record that we're attempting a call
                geminiStats.recordCall();

                // Wait for rate limiter slot
                await rateLimiter.waitForSlot();

                console.log(`[Gemini] ğŸš€ API í˜¸ì¶œ ì‹œì‘ (JSON: ${isJson})`);
                console.log(`[Gemini] í˜„ì¬ ë¶„ë‹¹ í˜¸ì¶œ ìˆ˜: ${rateLimiter.calls.length}/${rateLimiter.maxCallsPerMinute}`);

                // ëª¨ë¸ ëª©ë¡ - 2.0 ì´ìƒë§Œ ì‚¬ìš©, ì²« ë²ˆì§¸ ì‹¤íŒ¨ ì‹œ ë‹¤ìŒ ëª¨ë¸ ì‹œë„
                const modelNames = ["gemini-2.0-flash", "gemini-2.0-flash-lite", "gemini-2.0-pro"];
                let lastError: Error | null = null;

                for (const currentModel of modelNames) {
                    try {
                        console.log(`[Gemini] ğŸ”„ ëª¨ë¸ ì‹œë„: ${currentModel}`);

                        const model = genAI.getGenerativeModel({
                            model: currentModel,
                            generationConfig: {
                                maxOutputTokens: 300,
                                responseMimeType: isJson ? "application/json" : "text/plain"
                            }
                        });

                        const apiResult = isJson
                            ? await model.generateContent({
                                contents: [{ role: "user", parts: [{ text: prompt }] }]
                            })
                            : await model.generateContent(prompt);

                        const response = await apiResult.response;
                        const result = response.text();

                        // ì„±ê³µ
                        rateLimiter.recordCall();
                        geminiStats.recordSuccess();
                        cacheResponse(cacheKey, result);
                        console.log(`[Gemini] âœ… ${currentModel} ì„±ê³µ! (ì‘ë‹µ ê¸¸ì´: ${result.length}ì)`);
                        resolve(result);
                        return;
                    } catch (modelError: any) {
                        console.error(`[Gemini] ${currentModel} ì‹¤íŒ¨:`, modelError.message);
                        lastError = modelError;
                        // ë‹¤ìŒ ëª¨ë¸ ì‹œë„
                        continue;
                    }
                }

                // ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨
                throw lastError || new Error("ëª¨ë“  AI ëª¨ë¸ í˜¸ì¶œ ì‹¤íŒ¨");
            } catch (error: any) {
                console.error(`[Gemini] âŒ ì‹¤íŒ¨:`, error);
                console.error(`[Gemini] Error details:`, {
                    message: error.message,
                    stack: error.stack,
                    name: error.name,
                    status: error.status,
                    statusText: error.statusText
                });

                // Handle specific error codes
                const msg = error.message || "";
                const statusCode = error.status || (msg.match(/\d{3}/)?.[0]);
                let errorMsg = "";

                if (msg.includes("503") || statusCode === "503") {
                    errorMsg = "ğŸ”´ AI ì„œë²„ê°€ ì¼ì‹œì ìœ¼ë¡œ ê³¼ë¶€í•˜ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.";
                } else if (msg.includes("429") || msg.includes("RESOURCE_EXHAUSTED") || statusCode === "429") {
                    errorMsg = "â±ï¸ API ìš”ì²­ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.";
                } else if (msg.includes("404") || statusCode === "404") {
                    errorMsg = "ğŸ” AI ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.";
                } else if (msg.includes("API_KEY_INVALID") || msg.includes("invalid API key")) {
                    errorMsg = "ğŸš« API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.";
                } else if (msg.includes("leaked") || msg.includes("compromised")) {
                    errorMsg = "ğŸš« API í‚¤ê°€ ë…¸ì¶œë˜ì–´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆ í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.";
                } else if (msg.includes("403") || statusCode === "403") {
                    // 403ì€ ì—¬ëŸ¬ ì´ìœ ê°€ ìˆì„ ìˆ˜ ìˆìŒ - ì‹¤ì œ ë©”ì‹œì§€ í¬í•¨
                    errorMsg = `âš ï¸ API ì ‘ê·¼ ê±°ë¶€: ${msg.substring(0, 100)}`;
                } else if (msg.includes("PERMISSION_DENIED")) {
                    errorMsg = "âš ï¸ API ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤. Gemini API í™œì„±í™”ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.";
                } else {
                    errorMsg = `AI ì˜¤ë¥˜: ${msg.substring(0, 100)}`;
                }

                // Record failure with error message
                geminiStats.recordFailure(errorMsg);

                reject(new Error(errorMsg));
            }
        });
    });
}

export async function generateBattleText(animalName: string, characterName: string): Promise<string> {
    console.log("[generateBattleText] Starting generation for:", { animalName, characterName });
    console.log("[generateBattleText] API Key check:", apiKey ? `Present (${apiKey.substring(0, 10)}...)` : "MISSING");

    if (!apiKey) {
        throw new Error("API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (.env.local í™•ì¸ í•„ìš”)");
    }

    const prompt = `
    ë‹¹ì‹ ì€ ì°½ì˜ì ì¸ ì‘ê°€ì…ë‹ˆë‹¤. ë™ë¬¼ í…ìŠ¤íŠ¸ ë°°í‹€ ê²Œì„ì˜ ìºë¦­í„° ëŒ€ì‚¬ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

    ë™ë¬¼: ${animalName}
    ìºë¦­í„° ì´ë¦„: ${characterName}

    ì¡°ê±´:
    1. **ì ˆëŒ€ 100ìë¥¼ ë„˜ê¸°ì§€ ë§ˆì„¸ìš”.** (ê°€ê¸‰ì  50ì ë‚´ì™¸ë¡œ ì§§ê²Œ!)
    2. ë”± 1~2ë¬¸ì¥ìœ¼ë¡œ ì„íŒ©íŠ¸ ìˆê²Œ ì‘ì„±í•˜ì„¸ìš”.
    3. ìì‹ ê° ë„˜ì¹˜ê³ , ìê¸° ë™ë¬¼ì˜ íŠ¹ì§•ì„ ì‚´ë¦° ë‚´ìš©.
    4. ì•„ì´ë“¤ì´ ë³´ê¸°ì— ì ì ˆí•œ ë‚´ìš© (ë¹„ì†ì–´ ê¸ˆì§€).
    5. "~ë‹¤", "~ê¹Œ" ë“±ì˜ ë‹¹ë‹¹í•œ ì–´ë¯¸ ì‚¬ìš©.

    ì˜ˆì‹œ:
    "ë‚˜ëŠ” ì´ˆì›ì˜ ì§€ë°°ì ì‚¬ìì™•ì´ë‹¤! ë‚˜ì˜ ìš°ë ì°¬ í¬íš¨ë¥¼ ë“¤ì–´ë¼!"
    "ë‚ ë µí•œ ì¹˜íƒ€ì²˜ëŸ¼ ë„ˆë¥¼ ì œì••í•´ì£¼ì§€. ì¤€ë¹„ëŠ” ë˜ì—ˆë‚˜?"

    ì¶œë ¥:
  `;

    try {
        let text = await generateWithFallback(prompt, false);
        text = text.trim();

        // Remove quotes if present
        text = text.replace(/^["']|["']$/g, '');

        // Force truncate if too long (safety net)
        // User requested 98 characters limit
        if (text.length > 98) {
            // Cut at the last punctuation mark before 98 chars to keep it natural
            const cutIndex = text.lastIndexOf('.', 98);
            if (cutIndex > 0) {
                text = text.substring(0, cutIndex + 1);
            } else {
                // Fallback: just hard cut
                text = text.substring(0, 98) + "...";
            }
        }

        console.log("[generateBattleText] Success! Generated text:", text);
        return text;
    } catch (error: any) {
        console.error("[generateBattleText] Error:", error);
        // Propagate the error message clearly
        throw error;
    }
}

export async function judgeBattleWithAI(
    attackerName: string,
    attackerAnimal: string,
    attackerText: string,
    defenderName: string,
    defenderAnimal: string,
    defenderText: string
): Promise<{
    winner: 'attacker' | 'defender';
    reasoning: string;
    judgment: string;
}> {
    if (!process.env.GEMINI_API_KEY) {
        throw new Error("GEMINI_API_KEY is not set");
    }

    const prompt = `
    ë‹¹ì‹ ì€ "ë™ë¬¼ í…ìŠ¤íŠ¸ ë°°í‹€"ì˜ ê³µì •í•œ ì‹¬íŒì…ë‹ˆë‹¤. ë‘ ìºë¦­í„°ì˜ ë°°í‹€ í…ìŠ¤íŠ¸ë¥¼ ë³´ê³  ìŠ¹ìë¥¼ ê²°ì •í•´ì£¼ì„¸ìš”.

    [ê³µê²©ì]
    ì´ë¦„: ${attackerName} (${attackerAnimal})
    ëŒ€ì‚¬: "${attackerText}"

    [ë°©ì–´ì]
    ì´ë¦„: ${defenderName} (${defenderAnimal})
    ëŒ€ì‚¬: "${defenderText}"

    íŒì • ê¸°ì¤€:
    1. ëŒ€ì‚¬ì˜ ì°½ì˜ì„±ê³¼ ë°•ë ¥ (70%)
    2. ë™ë¬¼ì˜ íŠ¹ì§•ì„ ì–¼ë§ˆë‚˜ ì˜ í‘œí˜„í–ˆëŠ”ê°€ (30%)
    3. ì „íˆ¬ë ¥ ìˆ˜ì¹˜ëŠ” ë¬´ì‹œí•˜ê³  ì˜¤ì§ "í…ìŠ¤íŠ¸"ë¡œë§Œ íŒì •í•˜ì„¸ìš”.

    ì¶œë ¥ í˜•ì‹ (JSON Only):
    {
      "winner": "attacker" ë˜ëŠ” "defender",
      "judgment": "í•œ ì¤„ì§œë¦¬ ì§§ê³  ê·¹ì ì¸ íŒì • ë©˜íŠ¸ (ì˜ˆ: ê³µê²©ìì˜ í¬íš¨ê°€ í•˜ëŠ˜ì„ ì°Œë¦…ë‹ˆë‹¤!)",
      "reasoning": "ìŠ¹ë¦¬ ì´ìœ ë¥¼ ì•„ì´ë“¤ì—ê²Œ ì„¤ëª…í•˜ë“¯ì´ ì¹œì ˆí•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ 2ë¬¸ì¥ ë‚´ì™¸."
    }
  `;

    try {
        const jsonText = await generateWithFallback(prompt, true);
        const parsed = JSON.parse(jsonText);
        // Validate response structure slightly
        if (!parsed.winner || !parsed.judgment) {
            throw new Error("Invalid AI response structure");
        }
        return parsed;
    } catch (error) {
        console.error("Gemini Judge Error:", error);
        // Fallback if AI fails: Random or Length based
        return {
            winner: attackerText.length > defenderText.length ? 'attacker' : 'defender',
            judgment: "AI ì‹¬íŒì´ ì ì‹œ ìë¦¬ë¥¼ ë¹„ì› ë„¤ìš”! ë” ê¸¸ê³  ì •ì„±ìŠ¤ëŸ¬ìš´ ëŒ€ì‚¬ë¥¼ ì“´ ìª½ì´ ì´ê¹ë‹ˆë‹¤!",
            reasoning: "AI ì—°ê²° ìƒíƒœê°€ ì¢‹ì§€ ì•Šì•„ í…ìŠ¤íŠ¸ ê¸¸ì´ë¡œ íŒì •í–ˆìŠµë‹ˆë‹¤."
        };
    }
}
